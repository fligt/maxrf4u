{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp warp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial versus spectral \n",
    "\n",
    "> Lasagna versus spaghetti  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide \n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide  \n",
    "os.chdir('/home/frank/Work/Projecten/DoRe/viz/raw_nmf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide \n",
    "import numpy as np \n",
    "%matplotlib notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous sections we have converted and calibrated the original `.raw` spectral image data file into an analysis ready `.datastack` file. We will now gently start to learn how this three dimensional data cube is structured. Basically there are two ways to look at this data. One perspective is to think of the data cube as a stack of gray scale images. Every image has a different energy associated with it. If you remember from the previous section, these energies are the X-ray photon energies, expressed in kilo electron Volts (keV). Each image in the stack contains a distribution of intensities (photon counts). This is the lasagna view. \n",
    "\n",
    "Another way to think of the same data cube is to describe it as a rectangular bundle of spectra. At each spatial *(x,y)* location the data cube contains a spectrum with varying intensity along the third dimension *(z)* of the cube. This is the spaghetti view. We will come back to this in the next section.\n",
    "\n",
    "Very roughly speaking, the spatial intensity distribution within a slice located at a specific peak energy band represents the spatial distribution of a certain chemical element. For a start we can take a look at the largest peak in the max spectrum. This peak in the energy range of 6.1-6.7 keV is caused by the presence of the chemical element iron in the drawing. Because it is the largest peak, is is called the Fe_Ka (alpha) peak. Without prior knowledge of XRF physics (we will get to this topic later on) we can compute peak slice map for this energy band.  \n",
    "\n",
    "To do so, we need to read the required datasets with the `DataStack.read(<datapath>)` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maxrf4u import DataStack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataStack('RP-T-1898-A-3689.datastack') \n",
    "\n",
    "x_keVs = ds.read('maxrf_energies')\n",
    "y_max = ds.read('maxrf_maxspectrum') \n",
    "cube = ds.read('maxrf_cube', compute=False) # don't load into memory yet (too big)\n",
    "\n",
    "is_iron_Ka_band = (x_keVs > 6.1) * (x_keVs < 6.7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "..<img src=\"./images/30_spatial-verus-spectral_24343b47ce.png\">"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|echo: false  \n",
    "fig, ax = plt.subplots(figsize=[7, 3])\n",
    "ax.plot(x_keVs, y_max, color='r')\n",
    "ax.set_xlim([-1, 25])\n",
    "ax.set_xlabel('Energy [kev]')\n",
    "ax.set_ylabel('Intensity [counts]')\n",
    "ax.set_title('Max spectrum of Susanna (RP-T-1898-A-3689)') \n",
    "\n",
    "ax.fill_between(x_keVs, 0, 1, where=is_iron_Ka_band,\n",
    "                color='green', alpha=0.25, transform=ax.get_xaxis_transform(), label='Fe_Ka')\n",
    "ax.annotate('Fe_Ka band', xy=(6.7, 100),  xytext=(15, 15), textcoords='offset points', color='green', \n",
    "            arrowprops=dict(arrowstyle=\"->\", color='green'))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the iron distribution image by averaging over intensity at each pixel in the 60 images in the Fe_Ka energy band and plot the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide \n",
    "np.sum(is_iron_Ka_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeKa_slice = cube[:,:,is_iron_Ka_band].compute() # load only this slice into memory \n",
    "FeKa_map = FeKa_slice.sum(axis=2) / 60 # average over number of channels in the Fe_Ka band "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "..<img src=\"./images/30_spatial-verus-spectral_b068785248.png\">"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, [ax, ax1] = plt.subplots(ncols=2, sharex=True, sharey=True, figsize=[8, 5])\n",
    "\n",
    "ax.imshow(FeKa_map);\n",
    "ax.set_title('Fe_Ka map (unclipped)');\n",
    "ax1.imshow(FeKa_map, vmax=2);\n",
    "ax1.set_title('Fe_Ka map (clipped intensity)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the right we see here the distribution of iron associated with the iron-gall ink that Rembrandt used, as well as bright yellow speckles caused by iron particles present in the paper background. In order to make this visible, I had to clip the image intensity. On the left we see the very same image without clipping. Due to the high intensity of the iron speckles the contrast of the ink is very low.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image registration helper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compare the iron distribution map with a photo of the drawing. In order to make such a comparison we need to register the two images. Fully automated registration of images is a very important capability that is unfortunately out of scope here. Instead I have created a four point warping function `warp()` that will do the job if we provide the corresponding corner points of both the source and destiny image. These corner points can be be generated using the interactive `ImageRegistrationHelper()` function as shown below. This function displays interactive map widgets with markers that need to be positioned manually to corresponding landmarks on both the source (left) and destination (right) image. in our situation it is preferred to warp the visible image onto the iron map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|code-fold: true   \n",
    "susanna_highres_file = '/home/frank/Work/Projecten/DoRe/data/drawings/rma-web-highres/RP-T-1898-A-3689_highres.png'\n",
    "susanna_highres = plt.imread(susanna_highres_file)\n",
    "\n",
    "src_im = susanna_highres\n",
    "dst_im = np.clip(FeKa_map, a_min=0, a_max=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maxrf4u import ImageRegistrationHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8b6db8af224109927c1e5ac10f1195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Map(center=[2460.0, 2198.0], controls=(ZoomControl(options=['position', 'zoom_inâ€¦"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imreg = ImageRegistrationHelper(src_im, dst_im)\n",
    "imreg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/animation-ImageRegistrationHelper.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To register both images you first need to drag all eight markers to pairwise corresponding locations. When positioned correctly you can print the actual positions of the markers with the `.get_marker_coordinates()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_points = [[78.5, 204.6], [4340.1, 180.4], [4376.99, 4724.0], [110.1, 4766.3]]\n",
      "dst_points = [[24.7, 7.64], [1579.0, 10.2], [1563.8, 1666.0], [8.22, 1671.92]]\n"
     ]
    }
   ],
   "source": [
    "src_points, dst_points = imreg.get_marker_coordinates();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the corresponding source and destination marker points, the source image can be warped (registered) onto the destination image using the `warp()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|code-fold: true  \n",
    "susanna_highres_file = '/home/frank/Work/Projecten/DoRe/data/drawings/rma-web-highres/RP-T-1898-A-3689_highres.png'\n",
    "susanna_highres = plt.imread(susanna_highres_file)\n",
    "\n",
    "src_im = susanna_highres\n",
    "dst_im = FeKa_map \n",
    "\n",
    "# corner points for image registration \n",
    "src_points = [[78.5, 204.6], [4340.1, 180.4], [4376.99, 4724.0], [110.1, 4766.3]]\n",
    "dst_points = [[24.7, 7.64], [1579.0, 10.2], [1563.8, 1666.0], [8.22, 1671.92]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maxrf4u import warp  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imvis_reg_highres, extent = warp(src_im, dst_im, src_points, dst_points, rgba=False)\n",
    "imvis_reg, extent = warp(im_src, im_dst, pts_src, pts_dst, keep_scale=False, rgba=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For future calculations we will store the registered images and their extent in our `.datastack` file, using the `append()` function. In our further analysis we can simply use the registered images with the DataStack.read() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maxrf4u import append "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append(imvis_reg, 'imvis_reg', 'RP-T-1898-A-3689.datastack')\n",
    "append(imvis_reg_highres, 'imvis_reg_highres', 'RP-T-1898-A-3689.datastack')\n",
    "append(extent, 'imvis_extent', 'RP-T-1898-A-3689.datastack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "..<img src=\"./images/30_spatial-verus-spectral_89a3594115.png\">"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|code-fold: true \n",
    "ds = DataStack('RP-T-1898-A-3689.datastack')\n",
    "\n",
    "extent = ds.read('imvis_extent')\n",
    "imvis_reg_highres = ds.read('imvis_reg_highres')\n",
    "\n",
    "fig, [ax, ax1] = plt.subplots(ncols=2, figsize=[7, 4], sharex=True, sharey=True)\n",
    "\n",
    "ax.imshow(FeKa_map, vmax=2)\n",
    "ax1.imshow(imvis_reg_highres, extent=extent);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicely registered!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "\n",
    "from ipywidgets import Layout, HBox, VBox \n",
    "#import ipywidgets \n",
    "\n",
    "from ipyleaflet import Map, ImageOverlay, Marker, DivIcon, FullScreenControl, projections\n",
    "\n",
    "#from ipyleaflet import Map, Marker, projections, ImageOverlay, FullScreenControl, DivIcon\n",
    "\n",
    "from ipywidgets import Layout, GridBox, VBox, HBox, jsdlink \n",
    "from ipywidgets.embed import embed_minimal_html \n",
    "  \n",
    "import io \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import base64 \n",
    "import skimage.transform as skt \n",
    "import imageio \n",
    "import skimage \n",
    "\n",
    "import numpy as np\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export     \n",
    "class ImageRegistrationHelper(object): \n",
    "    '''Create interactive image registration. '''\n",
    "    \n",
    "    def __init__(self, src_im, dst_im, src_points=None, dst_points=None, scale_down=True): \n",
    "        \n",
    "        #\n",
    "         \n",
    "        # image shapes \n",
    "        src_h, src_w = self.src_h, self.src_w = src_im.shape[0:2]\n",
    "        dst_h, dst_w = self.dst_h, self.dst_w = dst_im.shape[0:2]\n",
    "        \n",
    "        \n",
    "        # scale base64 image down to smallest width \n",
    "        if  scale_down is True: \n",
    "            max_width = min([src_w, dst_w]) \n",
    "        else: \n",
    "            max_width = None \n",
    "        \n",
    "        # create base64 urls \n",
    "        src_url = _img_to_base64_url(src_im, max_width=max_width)\n",
    "        dst_url = _img_to_base64_url(dst_im, max_width=max_width)\n",
    "        \n",
    "        # create custom colored icons\n",
    "        w, h = 60, 20\n",
    "        colors = ['orange', 'green', 'red', 'blue'] \n",
    "        markers_html = [f\"\"\"<svg width=\"60px\", height=\"45px\">\n",
    "                <polygon points=\"20,25 40,25 30,40\" style=\"fill:{col};stroke:white;stroke-width:1\" />\n",
    "                <text x=\"10\" y=\"12\" font-size=\"10\" fill=\"black\">Drag me</text>\n",
    "                </svg>\"\"\" for col in colors] \n",
    "        icons = [DivIcon(html=html, bg_pos=(0, 0), icon_anchor=[30, 40], icon_size=[w, h]) for html in markers_html]\n",
    "\n",
    "        # prepare src and dst markers \n",
    "        self._src_markers = [] \n",
    "        self._dst_markers = [] \n",
    "        \n",
    "        src_locations = xy_to_latlon(imshape=[src_h, src_w], xy_points=src_points) \n",
    "        dst_locations = xy_to_latlon(imshape=[dst_h, dst_w], xy_points=dst_points) \n",
    "\n",
    "        # calculate map src and dst zoom levels to fit bounds (leaflet tiles are 256 pixels)\n",
    "        # see: https://leafletjs.com/examples/zoom-levels/ \n",
    "        src_zoom = -max([np.log2(np.ceil(src_w / 256)), np.log2(np.ceil(src_h / 256))]) - 2\n",
    "        dst_zoom = -max([np.log2(np.ceil(dst_w / 256)), np.log2(np.ceil(dst_h / 256))]) - 2 \n",
    "        \n",
    "        # create source maps for each corner \n",
    "        map_layout = Layout(height='200px', width='200px')\n",
    "        src_maps = []\n",
    "        for i, location in enumerate(src_locations):  \n",
    "            m = Map(center=[src_h/2, src_w/2], zoom=src_zoom+1, crs=projections['Simple'],  layout=map_layout, \n",
    "                    scroll_wheel_zoom=True, min_zoom=src_zoom-2, interpolation='nearest')\n",
    "\n",
    "            imo = ImageOverlay(url=src_url, bounds=[[-0.5, -0.5], [src_h - 0.5, src_w - 0.5]]) # bounds= SW NE corners\n",
    "            mrk = Marker(location=location, draggable=True, title='Drag me to landmark', icon=icons[i])\n",
    "            fsc = FullScreenControl()\n",
    "\n",
    "            m.add(imo)\n",
    "            m.add(fsc)\n",
    "            m.add(mrk)\n",
    "\n",
    "            self._src_markers.append(mrk)\n",
    "\n",
    "            m.remove(m.layers[0]) # hack to remove world map \n",
    "            src_maps.append(m)\n",
    "            \n",
    "        # create dst maps for each corner \n",
    "        dst_maps = []    \n",
    "        for j, location in enumerate(dst_locations):  \n",
    "            m = Map(center=[dst_h/2, dst_w/2], zoom=dst_zoom+1, crs=projections['Simple'],  layout=map_layout, \n",
    "                    scroll_wheel_zoom=True, min_zoom=dst_zoom-2, interpolation='nearest')\n",
    "\n",
    "            imo = ImageOverlay(url=dst_url, bounds=[[-0.5, -0.5], [dst_h - 0.5, dst_w - 0.5]]) # bounds= SW NE corners\n",
    "            mrk = Marker(location=location, draggable=True, title='Drag me to landmark', icon=icons[j])\n",
    "            fsc = FullScreenControl()\n",
    "\n",
    "            m.add(imo)\n",
    "            m.add(fsc)\n",
    "            m.add(mrk)\n",
    "\n",
    "            self._dst_markers.append(mrk)\n",
    "\n",
    "            m.remove(m.layers[0]) # hack to remove world map \n",
    "            dst_maps.append(m)\n",
    "        \n",
    "        # sync map widgets centers to marker locations  \n",
    "        # not exactly what I want, but close \n",
    "        # need probably something like a callback function on_drag or zoom  \n",
    "        # too complicated for now \n",
    "        #if center_markers: \n",
    "        #    for  mrk, mp in zip(self._src_markers, src_maps): \n",
    "        #        jsdlink([mrk, 'location'],[mp, 'center'])\n",
    "        #\n",
    "        #    for  mrk, mp in zip(self._dst_markers, dst_maps): \n",
    "        #        jsdlink([mrk, 'location'],[mp, 'center'])\n",
    "        #           \n",
    "        # combine maps     \n",
    "\n",
    "        src_hbox = HBox(src_maps)\n",
    "        dst_hbox = HBox(dst_maps)\n",
    "        \n",
    "        self._vbox = VBox([src_hbox, dst_hbox])\n",
    "        \n",
    "    def show(self): \n",
    "\n",
    "        return self._vbox \n",
    "    \n",
    "    \n",
    "    def get_marker_coordinates(self, verbose=True): \n",
    "        '''Extract marker point coordinates from widget. '''\n",
    "        \n",
    "        src_locations = [mrk.location for mrk in self._src_markers]\n",
    "        dst_locations = [mrk.location for mrk in self._dst_markers]\n",
    "        \n",
    "        src_points = latlon_to_xy([self.src_h, self.src_w], src_locations)\n",
    "        dst_points = latlon_to_xy([self.dst_h, self.dst_w], dst_locations)\n",
    "        \n",
    "        src_points = np.round(src_points, decimals=2).tolist()\n",
    "        dst_points = np.round(dst_points, decimals=2).tolist()\n",
    "        \n",
    "        if verbose: \n",
    "            print(f'src_points = {src_points}')\n",
    "            print(f'dst_points = {dst_points}')\n",
    "               \n",
    "        return src_points, dst_points \n",
    "    \n",
    "        \n",
    "        \n",
    "def _img_to_base64_url(img_data, max_width=None): \n",
    "    '''Filename or numpy array *img_data* is transformed into 256 bit color compressed base64 encoded url string. \n",
    "    \n",
    "    To reduce image size specify thumbnail `max_width`. \n",
    "    \n",
    "    Returns: url_string'''\n",
    "        \n",
    "    try: \n",
    "        # better than matplotlib use skimage.io.imread to avoid float64 explosion...\n",
    "        img = imageio.imread(img_data) # if img_data is an image file path \n",
    "    except: \n",
    "        img = img_data # otherwise assume img_data is an image like numpy array  \n",
    "        \n",
    "    shape = img.shape[0:2] # height and width only \n",
    "    h, w = shape \n",
    "    \n",
    "    # rescaling image if width > max_width \n",
    "    if max_width is not None:  \n",
    "        if w > max_width:\n",
    "            scale = max_width / w  \n",
    "            img = skt.rescale(img, scale, multichannel=True) \n",
    "            \n",
    "    # normalize \n",
    "    img_norm = (img - img.min()) / img.ptp()\n",
    "    \n",
    "    # reduce colors to 256 levels to keep base64 string size minimal \n",
    "    img_ubyte = skimage.util.img_as_ubyte(img_norm)\n",
    "    \n",
    "    # write to buffer \n",
    "    buff = io.BytesIO();\n",
    "    plt.imsave(buff, img_ubyte, format='png')\n",
    "   \n",
    "    \n",
    "    # convert to base64 string \n",
    "    base64_string = base64.b64encode(buff.getvalue()).decode(\"ascii\")\n",
    "    url_string = f'data:image/png;base64,{base64_string}' \n",
    "    \n",
    "    # let's close buffer just in case\n",
    "    buff.close()\n",
    "    \n",
    " \n",
    "    return url_string\n",
    "\n",
    "\n",
    "        \n",
    "def warp(im_src, im_dst, pts_src, pts_dst, keep_scale=True, rgba=True, alpha_color=[1, 0, 0]): \n",
    "    '''Opencv based homographic registration. Can return transparent overlay (rgba). \n",
    "    \n",
    "    Returns: *im_warped*, *extent* '''\n",
    "\n",
    "    src_h, src_w = im_src.shape[0:2]\n",
    "    dst_h, dst_w = im_dst.shape[0:2]\n",
    "    \n",
    "    if keep_scale: \n",
    "        scale = src_h / dst_h \n",
    "    else: \n",
    "        scale = 1\n",
    "\n",
    "    # calculate homography \n",
    "    hom, status = cv2.findHomography(pts_src, scale * pts_dst)\n",
    "\n",
    "    # Size is nearest integer scaled (width,height) of im_dst\n",
    "    size = round(scale * dst_w), round(scale * dst_h)\n",
    "    \n",
    "    # warp im_src onto destination \n",
    "    im_warped = cv2.warpPerspective(im_src, hom, size) \n",
    "    \n",
    "    # warp white onto destination to create mask \n",
    "    mask_src = np.ones([src_h, src_w])\n",
    "    mask_warped = cv2.warpPerspective(mask_src, hom, size) \n",
    "    \n",
    "    # calculate extent for plotting \n",
    "    h, w = im_dst.shape[0:2] \n",
    "    extent =  (0, w, h, 0) \n",
    "    \n",
    "    # convert into rgba image  \n",
    "    if rgba is True: \n",
    "        im_rgba = np.ones([h, w, 4])\n",
    "\n",
    "        # for single channel image \n",
    "        if len(im_src.shape) == 2:\n",
    "            # colorize\n",
    "            im_rgba[:,:,0:3] = alpha_color[0:3] \n",
    "            #  make alpha layer \n",
    "            im_rgba[:,:,3] = im_warped \n",
    "            \n",
    "        # otherwise assume image is rgb\n",
    "        elif len(im_warped.shape) == 3: \n",
    "            \n",
    "            # rgb channels\n",
    "            im_rgba[:,:,0:3] = im_warped[:,:,0:3]\n",
    "            # alpha channels \n",
    "            im_rgba[:,:,3] = mask_warped\n",
    "       \n",
    "        im_warped = im_rgba \n",
    "    \n",
    "    return im_warped, extent  \n",
    "\n",
    "\n",
    "# coordinate transformations \n",
    "\n",
    "def xy_to_latlon(imshape, xy_points=None): \n",
    "    '''Flip and exchange list with xy `points` into list of latitude-longitude locations. \n",
    "    \n",
    "    If `xy_points` are not specified, locations of the four image corner are returned. \n",
    "    \n",
    "    Returns: locations '''\n",
    "    \n",
    "    h, w = imshape \n",
    "    \n",
    "    # use image corners (pixel centric coordinates) \n",
    "    if xy_points is None:     \n",
    "        xy_points = [[0, 0], [w - 1, 0], [0, h - 1], [w - 1, h - 1]]\n",
    "    \n",
    "    xy_points = np.array(xy_points) # cast to numpy array if list\n",
    "    xy_points[:,1] = h - 1 - xy_points[:,1] # flip y \n",
    "    \n",
    "    locations = xy_points[:,::-1] # exchange x <-> y \n",
    "    \n",
    "    locations = locations.tolist() # Marker() expects list instead of array \n",
    "\n",
    "    return locations \n",
    "\n",
    "\n",
    "def latlon_to_xy(imshape, locations): \n",
    "    '''Flip and exchange list with latitude-longitude `locations` into list of xy_points. \n",
    "    \n",
    "    Returns: xy_points '''\n",
    "    \n",
    "    h, w = imshape \n",
    "    \n",
    "    locations = np.array(locations) # cast to numpy array if list \n",
    "    locations[:,0] = h - 1 - locations[:,0] # flip y  \n",
    "    \n",
    "    xy_points = locations[:,::-1] # exchange x <-> y \n",
    "\n",
    "    return xy_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#|hide \n",
    "\n",
    "## Issues\n",
    "\n",
    "* Need a fast and user friendly way to inspect and improve and existing image registration. \n",
    "* Add option to select base64 encoding or python matplotlib? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
