# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/60_peakmaps.ipynb (unless otherwise specified).

__all__ = ['get_cube_slices', 'plot_cube_slices', 'get_peakmaps', 'multi_plot', 'smooth_compton']

# Cell

import numpy as np
import scipy.interpolate as sip
import scipy.signal as ssg
from maxrf4u import DataStack, HotmaxAtlas
from dask.diagnostics import ProgressBar
import matplotlib.pyplot as plt
import skimage.exposure as ske
import skimage.morphology as skm
from scipy.ndimage import gaussian_filter1d


def get_cube_slices(datastack_file, tail_clip=0.05):
    '''Computes fitted and clipped Gaussian peak shapes for all hotmax pixels.

    Returns: `peak_slices`, `y_gauss_list` '''

    # read stuff from datastack
    ds = DataStack(datastack_file)

    x_keVs = ds.read('maxrf_energies')
    hotmax_pixels = ds.read('hotmax_pixels')
    hotmax_spectra = ds.read('hotmax_spectra')
    hotmax_baselines = ds.read('hotmax_baselines')

    peak_idxs = hotmax_pixels[:,2]

    # get slices by fitting gaussian to corresponding hotmax spectrum and baseline
    y_gauss_list = []
    peak_slices = []

    # step 1: create tail clipped gaussians
    for i, peak_idx in enumerate(peak_idxs):

        y_hot = hotmax_spectra[i]
        baseline = hotmax_baselines[i]
        y_gauss_fit, baseline = _fit_gaussian(x_keVs, y_hot, peak_idx, baseline=baseline)

        y_gauss_flat =  y_gauss_fit - baseline

        # clip peak tails below tail_clip level
        mask = np.ones_like(y_gauss_flat)
        is_below_clip = y_gauss_flat < tail_clip
        mask[is_below_clip] = 0
        y_gauss_fit_clipped = y_gauss_fit * mask

        y_gauss_list.append(y_gauss_fit_clipped)

        # peak slices
        peak_domain_idxs = np.argwhere(y_gauss_fit_clipped)
        i = peak_domain_idxs.min()
        j = peak_idx
        k = peak_domain_idxs.max()

        peak_slices.append([i,j,k])

    return peak_slices, y_gauss_list



def _gaussian(x, x0, sigma):
    '''Normal distribution around `x0` with standard deviation `sigma`.'''

    y = np.exp(-0.5 * ((x - x0) / sigma)**2)

    return y


def _fit_gaussian(x, y, peak_idx, rel_height=0.2, baseline=None):
    '''Fit single gaussian distribution at `rel_height`.

    Returns: `y_gauss`, `baseline`
    '''

    # just a single peak
    [widths], [width_height], [left_ips], [right_ips] = ssg.peak_widths(y, [peak_idx], rel_height=rel_height)

    # create energy interpolation
    keV_ipol = sip.interp1d(np.arange(len(x)), x)

    left_x = keV_ipol(left_ips)
    right_x = keV_ipol(right_ips)

    # pick smallest half width at rel_height
    dx_left = left_x - x[peak_idx]
    dx_right = right_x - x[peak_idx]

    dx = sorted([dx_left, dx_right])[0]

    # create baseline
    if baseline is None:
        baseline = np.zeros_like(y)

    y_norm = (width_height - baseline[peak_idx]) / (y[peak_idx] - baseline[peak_idx])

    # assert that y_norm is positive
    assert y_norm > 0, f"Can't fit Gaussian for peak below baseline for peak index {peak_idx}."

    # calculate corresponding sigma
    sigma = np.sqrt(-dx**2 / (2 * np.log(y_norm)))

    # calculate gaussian with baseline
    y_gauss = (y[peak_idx] - baseline[peak_idx]) * _gaussian(x, x[peak_idx], sigma) + baseline

    return y_gauss, baseline


# Plotting

def plot_cube_slices(datastack_file, ax=None, tail_clip=0.05, xlim=[-1, 24]):

    # read data
    ds = DataStack(datastack_file)
    x_keVs = ds.read('maxrf_energies')
    y_max = ds.read('maxrf_maxspectrum')

    if ax is None:
        fig, ax = plt.subplots(figsize=[9, 4])

    y_gauss_list = get_cube_slices(datastack_file, tail_clip=tail_clip)[1]

    for y_gauss in y_gauss_list:

        ax.fill_between(x_keVs, y_gauss)

    ax.plot(x_keVs, y_max, color='r', alpha=0.5, label='max spectrum')
    ax.fill_between(x_keVs, y_max, color='r', alpha=0.2)

    _add_hotlines_ticklabels(datastack_file, ax)

    ax.set_xlim(xlim)

    ax.set_xlabel('energy [keV]')
    ax.set_ylabel('intensity [#counts]')

    ax.legend()

    plt.tight_layout()

    return ax



def _add_hotlines_ticklabels(datastack_file, ax, clip_vline=True):
    '''Utility function. Adds hotlines and tick labels to plot `ax`.

    '''
    # read hotlines data
    ds = DataStack(datastack_file)
    x_keVs = ds.read('maxrf_energies')
    peak_idxs = ds.read('hotmax_pixels')[:, 2]

    secax = ax.secondary_xaxis('top')

    secax.set_xticks(x_keVs[peak_idxs])

    ymin, ymax = ax.get_ylim()

    # clip vlines at y=0
    if clip_vline:
        ax.vlines(x_keVs[peak_idxs], 0, 1.2*ymax, color='r', alpha=0.2, zorder=9-30)
        ax.set_ylim(ymin, ymax)

    # do not clip vlines
    else:
        for x in x_keVs[peak_idxs]:
            ax.axvline(x, color='r', alpha=0.2, zorder=9-30)

    secax.set_xticks(x_keVs[peak_idxs])
    secax.set_xticklabels(range(len(peak_idxs)), fontsize=6, color='r')
    secax.tick_params(color=[1, 0.5, 0.5], pad=0)

    return ax


# peak maps

def get_peakmaps(datastack_file, slices, norm=True, verbose=False):
    '''Integrate peak `slices`  into peak maps and keV maps.

    Returns: peak_maps, keV_maps'''

    ds = DataStack(datastack_file)
    x_keVs = ds.read('maxrf_energies')
    cube = ds.read('maxrf_cube', compute=False) # don't load into memory yet (too big)

    peak_maps = []
    keV_maps = []

    # skipping baseline correction for now
    # can not be based on super slices

    n_channels = len(x_keVs)

    with ProgressBar():

        for i, [si, sj, sk] in enumerate(slices):

            peak_slice = cube[:,:,si:sk+1].compute()

            # average over slice layers
            print(f'Computing peak_map {i}/{len(slices)-1}')#, end='\r')
            d = peak_slice.shape[-1]
            peak_map = np.sum(peak_slice, axis=2) / d

            if norm:
                peak_map = peak_map / peak_map.max()

            keV_idx_map = si + np.argmax(peak_slice, axis=2)
            keV_map = x_keVs[keV_idx_map]

            peak_maps.append(peak_map)
            keV_maps.append(keV_map)

    return peak_maps, keV_maps



def multi_plot(*images, hot_pixel=None, titles=None, roi_list=None, axis_off=False,
               sharex=True, sharey=True, vmin=None, vmax=None, cmap='viridis',
               fontsize='medium', zoom_xyc=None, zoom_half_wh=[100, 100]):
    '''Inspect multiple images simultaneously...

    Fold along multiple rows if n > 4'''

    nrows_max = 4
    n_img = len(images)

    nrows = (n_img // nrows_max) # completely filled rows
    rest = n_img % nrows_max
    if rest != 0:
        nrows = nrows + 1

    if n_img <= nrows_max:
        ncols = n_img
    else:
        ncols = nrows_max

    figsize = [9, 5 + 1.3 * (nrows -1)]

    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, squeeze=False, sharex=sharex, sharey=sharey)

    for i, img in enumerate(images):

        axs.flatten()[i].imshow(img, cmap=cmap, vmin=vmin, vmax=vmax)

        if hot_pixel is not None:
            hot_yi, hot_xi, hot_zi = hot_pixel
            axs.flatten()[i].scatter(hot_xi, hot_yi, color='r')

        if zoom_xyc is not None:
            xc, yc = zoom_xyc
            w_ha, h_ha = zoom_half_wh

            axs.flatten()[i].set_xlim(xc - w_ha, xc + w_ha)
            axs.flatten()[i].set_ylim(yc + h_ha, yc - h_ha)

        if roi_list is not None:
            add_roi_patches(axs.flatten()[i], roi_list)

    if titles is not None:
        for i, t in enumerate(titles):
            axs.flatten()[i].set_title(t, fontsize=fontsize)

    # seems to have no effect:
    for i in range(n_img, nrows * ncols):
        axs.flatten()[i].axis('off')
    # therefore trying this:
    if axis_off:
        axs_flat = axs.flatten()
        for ax in axs_flat:
            ax.set_axis_off()

    fig.subplots_adjust(hspace=0.1, wspace=0.1)

    plt.tight_layout()

    return fig, axs


# better baseline estimation ?

def smooth_compton(y_sum):
    '''Create smoothed Compton background from sum spectrum `y_sum`.

    Just a quick hack to remove little peaks. '''

    # smooth
    y_filtered = gaussian_filter1d(y_sum, 50)

    # replace middle part
    y_compton = y_sum.copy()
    m = 600
    n = 1750
    y_compton[m:n] = y_filtered[m:n]

    # make exponential left tail
    y_compton[0:m] = y_compton[m] * np.linspace(0, 1, m)**4

    # smooth to get rid of tiny discontinuities
    y_compton = gaussian_filter1d(y_compton, 10)

    return y_compton